#+TITLE: Elementi di Calcolo delle Variazioni
#+AUTHOR: Dario Balboni
#+DATE:
#+LANGUAGE: it
#+OPTIONS: H:4 toc:nil
#+LaTeX_class_options: [a4paper, 11pt]
#+LaTeX_header: \hypersetup{colorlinks=true,linkcolor=black,citecolor=black,filecolor=black,urlcolor=black}
#+LaTeX_header: \usepackage[AUTO]{babel}
#+LaTeX_header: \usepackage[left=20mm,textwidth=167mm,headsep=8mm,footskip=20pt,top=2.5cm,bottom=2.5cm]{geometry}
#+LaTeX_header: \input{latex-abbreviations}

\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
\setlist{nosep}
\linespread{1.2}
\titlespacing\section{0pt}{0pt}{0pt}
\titlespacing\subsection{0pt}{0pt}{0pt}
\titlespacing\subsubsection{0pt}{0pt}{0pt}

* Metodo indiretto (pp. 8-50)
  Roadmap:
  1. *Condizioni Necessarie*: ELE + BC
  2. *Risolvere le equazioni*
  3. *Dimostrare che le soluzioni sono minimi* via convessità o lemma trivial

** Idee generali
  #+CAPTION: Idea generale dell'andamento a seconda della Lagrangiana
  | Lagrangiana             |                                 |
  |-------------------------+---------------------------------|
  | Strett. convessa in $p$ | Esistenza ed Unicità            |
  | Non convessa            | Guai                            |
  | Convessa ma non strett. | Rischi per Unicità e Regolarità |

  #+CAPTION: Vincoli generati dal metodo diretto con la variazione prima
  | Vincoli ad un estremo       | Condizioni di Dirichlet $u(b) = B$                  |
  | No vincoli ad un estremo    | Condizioni di von Neumann $\dot{u}(b) = 0$          |
  | Vincoli in punto intermedio | Troppe condizioni: se sono sfortunato non ha minimo |
** Trovare il minimo
  - (*Variazione prima*) Se $x_0 \in \argmin \lrg{F(x) : x \in \bbX}$ allora per ogni curva $\gamma$ si ha $\delta F(x_0, \gamma) = 0$ quando esiste.
    Se $\bbX$ è uno spazio affine e $V$ il suo spazio vettoriale di riferimento posso considerare come curve le rette lungo una direzione.
  - (*FLCV*) Sia $f: [a,b] \rar \bbR \in \cC^0$ e supponiamo che $\int_a^b f(x) v(x) \de x = 0 \quad \forall v \in V$ allora $f(x) = 0$ per ogni $x \in [a,b]$.
    Questo lemma vale quando la chiusura di $\Span(V)$ rispetto alla convergenza uniforme sui compatti contenuti in $[a,b]$ meno un numero finito di punti è tutto $\cC^0$.
    In particolare vale per $V = \cC^\infty_c(a,b)$.

    In versione Lebesgue si ha: $f: (a, b) \rar \bbR \in \cL^2(a, b)$ e supponiamo che $\int_a^b f(x) v(x) \de x = 0$ per ogni $v \in \cC^\infty_c(a, b)$. Allora $f(x) \equiv 0$ per quasi ogni $x \in (a, b)$.
  - (*DBR*) Sia $f: [a, b] \rar \bbR \in \cC^0$ e supponiamo che $\int_a^b f(x) v(x) \de x = 0 \quad \forall v \in V$ tali che $\int_a^b v(x) \de x = 0$ allora $f(x)$ è costante in $[a,b]$.
    Vale per gli stessi $V$ di cui sopra. Notiamo inoltre che le funzioni del tipo $\dot{v}(x)$ con $v \in \cC^\infty_c$ sono tutte e sole le $w \in \cC^\infty_c$ a media nulla.
  - /Osservazione/: Se $F(u)$ dipende da $u$ e da $\dot u$ non posso mettere vincoli su $\dot u$ altrimenti il minimo molto probabilmente non esiste e l'inf è quello senza condizione.
  - (*ELE*) Sia dato un funzionale $F(u) := \int_a^b L(x, u(x), \dot u(x)) \de x$ dove $L: [a, b] \times \bbR \times \bbR \rar \bbR$ con variabili $(x, s, p)$.
    1. *Prima forma integrale della variazione prima*: Se $L, u, v \in \cC^1$ si ha $\delta F(u, v) = \int_a^b \lrq{L_s(x, u, \dot u) v + L_p(x, u, \dot u) \dot v} \de x$
    2. *Seconda forma integrale della variazione prima*: Se $L, u \in \cC^2$, $v \in \cC^1$ e $v(a) = v(b) = 0$ allora $\delta F(u, v) = \int_a^b \lrq{L_s(x, u, \dot u) - (L_p(x, u, \dot u))'} v \de x$

    /ELE Differenziale/: Se $L, u \in \cC^2$ ed $u$ è punto di minimo per $F$ si ha $\lrq{L_p(x, u, \dot u)}' = L_s(x, u, \dot u)$.
    L'equazione espansa è $L_{px} + L_{ps} \dot u + L_{pp} \ddot u = L_s$ che si può scrivere in forma normale se $L_pp \neq 0 \quad \forall x \in [a,b]$.
    
    /ELE-DBR/: $L_p(x, u(x), \dot u(x)) = c + \int_a^x L_s(t, u(t), \dot u(t)) \de t$ (serve meno regolarità in $L$, basta $L \in \cC^1$).

    /ELE Erdmann/: Se $L$ non dipende da $x$ allora si ottiene $L_p(u, \dot u) \dot u = c + L(u, \dot u)$ (ha solo ordine uno).
    È equivalente alla ELE classica solo nei punti in cui $\dot u(x) \neq 0$.

    /Condizioni di Neumann/: Se sono soggetto alla condizione $u(a) = A$ ottengo nell'altro estremo la condizione $L_p(x, u, \dot u) = 0$.

    /Ultrageneralizzazione/: Se $L$ dipende da più derivate successive ed $u$ è un punto di minimo per FLCV troviamo la formula
    $$\sum_{i=1}^k (-1)^{i+1} \frac{\de^i}{\de x^i} L_{p_i} (x, u, \dot u, \ldots, u^{(k)}) = L_s (x, u, \dot u, \ldots, u^{(k)})$$
** Dimostrare che è il minimo
*** Convessità
    Consideriamo $F(u) = \int_a^b L(x, u(x), \dot u(x)) \de x$ con DBC e supponiamo
    1. Abbastanza regolarità: $L \in \cC^2$
    2. $u_0(x)$ sia soluzione della prima forma integrale di ELE (ELE-DBR)
    3. $\forall x \in [a, b]$ la funzione $(s, p) \mapsto L(x, s, p)$ è convessa

    Allora $u_0$ è punto di minimo per il problema con le DBC.
    
    Se inoltre $L(x, \cdot, cdot)$ è strettamente convessa si ha che $u_0$ è l'unico punto di minimo.
*** Lemma Trivial
    Sia $\bbX$ un insieme e siano $F, G: \bbX \rar \bbR$ due funzioni tali che
    1. $F(x) \ge G(x) \quad \forall x \in \bbX$
    2. $x_0 \in \bbX$ è punto di minimo per $G$
    3. $F(x_0) = G(x_0)$

    Allora $x_0$ è punto di minimo per $F$.

    Inoltre se $x_0$ è unico punto di minimo per $G$ è unico anche per $F$.
** Point-to-curve Problems
   Dato un punto $(a, A) \in \bbR^2$ ed una funzione $\phi: \bbR \rar \bbR$ con $F(u) = \int_a^b L(x, u, \dot u) \de x$ vogliamo minimizzare $F(u)$ al variare delle coppie $(u, b)$ tali che $u \in \cC^1[a,b], u(a) = A, u(b) = \phi(b)$.

   Se $L \in \cC^2, \phi \in \cC^1$ e $(u_0, x_0)$ è punto di minimo, allora si ottiene, oltre alla solita ELE e DBC, un'altra condizione, detta di transversality:
   $$L_p(x_0, u_0(x_0), \dot u_0(x_0)) (\dot u_0(x_0) - \dot \phi(x_0)) = L(x_0, u_0(x_0), \dot u_0(x_0))$$
* Metodo diretto (pp. 85-96)
  Roadmap:
  1. *Formulazione Debole*: Estendere $F(u)$ ad un ambiente più ampio (Sobolev)
  2. *Compattezza*: Dimostrare che i sottolivelli di $F(u)$ sono compatti rispetto a qualche nozione di convergenza
  3. *Semicontinuità*: Dimostrare che $F$ è SCI rispetto alla stessa nozione di convergenza, ovvero che i minimi esistono nell'ambiente più vasto
  4. *Regolarità*: Dimostrare che i punti di minimo in realtà stanno anche nell'ambiente originario
     1. *Equazione di Eulero debole*
     2. *Guadagno della prima derivata*
     3. *Bootstrap*

  Fatto ciò bisogna poi trovare i punti di minimo.
** Dimostrazione della Compattezza
    Abbiamo $F(u) := \int_a^b (\abs{\dot u}^p + g(x, u)) \de x$.
    Sotto quali ipotesi possiamo dedurre che $F(u_n) \le M \implies u_{n_k} \rar u_\infty$ in un certo senso?
    
    Questo certo senso significa $u_n \rar u_\infty$ uniformemente e $\dot u_n \rhu^{\cL^2} \dot u_\infty$.

    /Risposta/: Se ho una stima del tipo $g(x, s) \ge - A - B \abs{s}^q$ con $q < p$ e $A, B$ reali.

    /Dimostrazione/:
    1. $\norm{\dot u_n}_{\cL^p}^p = \int_a^b \dot u_n^2 = F(u_n) - \int_a^b g(x, u_n(x)) \de x \le F(u_n) + A (b-a) + B \int_a^b \abs{u_n(x)}^q$.
       Per poter stimare questo numero usiamo una delle seguenti due condizioni per ottenere limitatezza globale:
       1. Se si ha una DBC del tipo $u(a) = C$ allora stimando con l'equihölderianità si ha una limitazione globale dipendente dalla norma della derivata: $\abs{u_n(x)} \le \norm{\dot u_n}_{\cL^p} \abs{b - a}^{\frac{1}{p'}}$
       2. Avere una condizione integrale del tipo $\int_a^b \abs{u_n(x)}^s \le T$ che ci permette di avere limitatezza in un punto usando il teorema della media integrale e poi procedere come in (a)
       3. Avere $g(x, s)$ limitata dal basso, ovvero $g(x, s) \ge -D$, assieme ad una stima del tipo $g(x, u) \ge K \abs{u}^e - N$ con $K > 0$.
          In questo caso la stima sulle derivate si ha dalla stima dal basso: $\norm{\dot u_n}_{\cL^p} = F(u_n) - \int_a^b g(x, s) \de x \le F(u_n) - D (a-b) \le M - D (a-b)$.
	  Mentre la stima integrale si ottiene dalla seconda disuguaglianza: $\norm{u_n}_{\cL^e} \le \frac{1}{K} \lrq{N + \int_a^b g(x, u) \de x} \le \frac{1}{K} \lrq{N + F(u_n)} \le \frac{N + M}{K}$.

       Nei casi (a) e (b) segue $\norm{\dot u_n}_{\cL^p}^p - B (b-a)^{2 - \frac{1}{p}} \norm{\dot u_n}_{\cL^p}^q \le \norm{\dot u_n}_{\cL^p}^p - B \int_a^b \abs{u_n(x)}^q \le M + A (b-a)$.
       Ora se $q < p$ si ha una disuguaglianza su $\norm{\dot u_n}_{\cL^p}$ che è soddisfatta solo sui punti interni, da cui si ottiene $\norm{\dot u_n}_{\cL^p} \le M'$.

       E quindi si ha anche (essendo $[a,b]$ limitato) che $\norm{\dot u_n}_{\cL^2} \le M''$ (infatti $\abs{x}^p \le 1 + \abs{x}^2$) ed analogamente per $\norm{u_n}_{\cL^2}$.
    2. Per compattezza debole delle palle in $\cL^2$ (Hilbert separabile) otteniamo che $\exists \dot u_{n_k} \rhu^{\cL^2} v_\infty$.
    3. Per la stima sull'Hölderianità delle $u_n$ abbiamo che le $u_{n_k}$ sono $\frac{1}{p}$ Hölder con costante comune e sono equilimitate per via del dato al bordo e della stima con l'equihölderianità.
       Inoltre abbiamo precedentemente ottenuto una limitazione globale.
    4. Per Ascoli-Arzelà si ha, a meno di altre sottosuccessioni, $u_{n_k} \rar u_\infty$ uniformemente in $[a,b]$
    5. Dal passaggio al limite nella formula di integrazione per parti otteniamo che $v_\infty = \dot u_\infty$

    Questo ci fa ottenere la convergenza $u_n \rar u_\infty$ uniformemente e $\dot u_n \rhu^{\cL^p} \dot u_\infty$.
** Dimostrazione della Semicontinuità
   Sia $F(u) = \int_a^b \psi(u(x)) + g(x, u) \de x$.
   
   /Parte in $g$/:
   1. Se $g$ è continua e $u_n \rar u_\infty$ uniformemente allora $\int_a^b g(x, u_n(x)) \de x \rar \int_a^b g(x, u_\infty(x)) \de x$.
   2. Se $g$ è SCI e limitata dal basso posso usare il lemma di Fatou per avere la semicontinuità di questa parte di integrale.

   /Parte in $\psi$/: Se $\psi$ è convessa
* Risoluzione Equazioni Differenziali con variazioni (pp. 97-108)
  Supponiamo di avere il problema $\ddot u = h(u, x)$ con $u(a) = A, u(b) = B$. Notiamo che questo *non* è un problema di Cauchy classico.
  Vogliamo studiare esistenza, unicità e regolarità della soluzione.

  - (*Problema di minimo equivalente*) Possiamo trasformare questo problema come ELE del problema di minimo di $F(u) = \int_a^b \frac{(\dot u)^2}{2} + g(u, x) \de x$ dove $g(s, x) = \int_a^s h(t, x) \de t$.
    Sfruttiamo il metodo diretto per ottenere informazioni sul problema.
    
    Nel caso in cui uno dei due vincoli iniziali sia con $\dot u(c) = C$ al bordo (ovvero $c = a$ oppure $c = b$) allora abbiamo due possibilità
    1. Modifico il funzionale come $F(u) = \int_a^b \frac{1}{2} (\dot u)^2 - C \dot u + g(u, x) \de x$ e non metto la condizione, ottenendo come condizione in corso d'opera $\dot u(c) = C$
    2. Cambio variabili e pongo $v(x) = u(x) - Cx$ e trovo che equazione risolve $v$
       
    Il primo metodo modifica la parte in $p$ della Lagrangiana (può portare a problemi di convessità), la seconda modifica $g$ (possibili problemi di integrazione di $h$).
  - (*Soluzioni periodiche*) Per la ricerca di soluzioni periodiche devo, al variare di $\lambda$ periodo, minimizzare con $u(a) = u(a + \lambda)$ nell'intervallo $[a, a + \lambda]$.
    Se ci riesco ottengo le NBC $\dot u(a) = \dot u(a + \lambda)$ e, per unicità della soluzione del problema di Cauchy, so che la soluzione è periodica.
* Funzioni SCI e Rilassamento (pp. 109-127)
  Tutto ciò che c'è in questa sezione suppone $(\bbX, d)$ metrico.
  - (*Funzioni semicontinue inferiori*) Una funzione $f: \bbX \rar \bar\bbR$ si dice semicontinua inferiore se vale uno dei seguenti fatti equivalenti:
    1. $\forall x \in \bbX \quad \liminf_{y \rar x} f(y) \ge f(x)$
    2. Per ogni successione $x_n \rar x_\infty$ vale $\liminf_{n \rar +\infty} f(x_n) \ge f(x_\infty)$
    3. Per ogni $M \in \bbR$ il sottolivello $\lrg{x \in \bbX : f(x) \le M}$ è chiuso
    4. L'epigrafico di $f$ $\lrg{(x, y) \in \bbX \times \bbR \mid y \ge f(x)}$ è chiuso in $\bbX\times\bbR$
  - (*Chiusura per sup*) Data una famiglia $\lrg{f_i}_{i \in I}$ di funzioni SCI, allora $s(x) := \sup \lrg{f_i(x) : i \in I}$ è SCI.
  - (*Inviluppo SCI*) Data $f: \bbX \rar \bar\bbR$ si definisce /inviluppo SCI/ $\hat f(x) := \sup \lrg{g(x) \mid g \SCI, g(y) \le f(y) \forall y \in \bbX}$
  - (*Rilassamento*) Data $f: \bbX \rar \bar\bbR$ si definisce /rilassamento/ $\bar f(x) := \inf \lrg{\liminf_{n \rar +\infty} f(x_n) \mid x_n \rar x}$
  - (*Lemma fondamentale*) Vale $\forall x \in \bbX, \forall r, \epsilon > 0 \exists y \in \bbX \tc d(x, y) \le r$ e $f(y) \le \bar f(x) + \epsilon$
  - (*Recovery sequence*) Una successione $x_n \rar x$ si dice recovery sequence per $f$ in $x$ se $\lim_{n \rar +\infty} f(x_n) = \bar f(x)$.
    Si dimostra che esistono delle recovery sequence per ogni punto $x$.
  - (*Coercività*) Una funzione $f: \bbX \rar \bar\bbR$ si dice coerciva se $\exists K \subseteq X$ compatto tale che $\inf_{x \in K} f(x) = \inf_{x \in X} f(x)$.
  - (*Proprietà di Rilassamento ed Inviluppo SCI*)
    1. $\forall f$ si ha $\hat f = \bar f$
    2. $\bar f(x) \le f(x)$
    3. $\bar f(x) = \min\lrg{\liminf_{n \rar +\infty} f(x_n) \mid x_n \rar x}$
    4. $\bar f$ è SCI
    5. $\forall A \subseteq \bbX$ aperto vale che $\inf_{x \in A} f(x) = \inf_{x \in A} \bar f(x)$
    6. Se $f$ è coerciva (con compatto $K$) allora $\bar f$ ha minimo in $\bbX$ e vale $\inf_{x \in \bbX} f(x) = \min_{x \in K} \bar f(x)$.
    7. Sia $x_n$ una successione infizzante per $f$ e supponiamo che $x_n \rar x_\infty$. Allora $x_\infty$ è un punto di minimo di $\bar f$.
  - Se $\lrg{f(x) < M}$ è non vuoto e contenuto in un compatto allora tutte le successioni infizzanti per $f$ hanno almeno una sottosuccessione che tende ad un punto di minimo di $\bar f$.
  - Se $\bar f$ ha un unico punto di minimo, e $\lrg{f(x) < M}$ è non vuoto e contenuto in un compatto, allora tutte le successioni infizzanti tendono (senza sottosuccessioni) al punto di minimo di $\bar f$.
    Anzi, le successioni infizzanti di $f$ sono tutte e sole le recovery sequence del punto di minimo di $\bar f$.
  - (*Stabilità per perturbazioni continue*) Se $\phi: \bbX \rar \bbR$ è continua allora $\bar{f + \phi} = \bar f + \phi$.
    In generale vale solo che $\bar{f + \phi} \ge \bar f + \bar \phi$.
  - (*Uguaglianza con il rilassato*) Vale $f = \bar f \sse f \SCI$.
  - (*Sottoinsieme denso in energia*) Sia $f: \bbX \rar \bbR$. Un sottoinsieme $D \subseteq \bbX$ si dice /denso in energia per $f$/ se $\forall x \in \bbX: \exists \lrg{x_n} \subseteq D$ tale che $x_n \rar x$ e $f(x_n) \rar f(x)$.
    (Se $f$ è continua allora denso in energia sse denso).
  - (*Estensione per rilassamento*) Supponiamo di avere $f: A \rar \bar\bbR$ una funzione da $A \subseteq \bbX$ e di volerla "estendere" in un qualche senso a tutto $\bbX$.
    Allora posso porre $\tilde f = \bar g$ dove $g(x) = f(x) \text{ se } x \in A$ e vale $+\infty$ altrimenti. 
*** Dimostrare una disuguaglianza di funzioni da una su un denso
    Siano $\phi, \psi: \bbX \rar \bar\bbR$ e sia $D \subseteq \bbX$.
    Se valgono:
    1. $\phi(x) \le \psi(x)$ per ogni $x \in D$
    2. $D$ è denso in energia per $\psi$
    3. $\phi$ è SCI
      
    Allora $\phi(x) \le \psi(x)$ $\forall x \in \bbX$.
*** Mostrare che $g$ è il rilassato di $f$ -- Strategia 1
    Se valgono:
    1. *Liminf inequality*: $\forall x_n \rar x$ vale $\liminf_{n \rar +\infty} f(x_n) \ge g(x)$
    2. *Limsup inequality*: $\forall x \in \bbX$, $\exists x_n \rar x$ tale che $\limsup_{n \rar +\infty} f(x_n) \le g(x)$ (ma basterebbe il $\liminf$)
     
    Allora $g = \bar f$.
*** Mostrare che $g$ è il rilassato di $f$ -- Strategia 2
    Date $f, g: \bbX \rar \bar\bbR$, se vale che
    1. $g$ è SCI
    2. $g(x) \le f(x) \quad \forall x \in \bbX$
    3. $\exists D \subseteq \bbX$ denso in energia per $g$ tale che $\forall x \in D \quad \exists x_n \rar x \tc \limsup_{n \rar +\infty} f(x_n) \le g(x)$ (ma basterebbe il $\liminf$)
    
    Allora $g$ è il rilassato di $f$.
*** Rilassato nel caso di $f$ quasi-periodica
    Supponiamo di voler minimizzare $F(u) := \int_a^b f(\dot u) + g(u, x) \de x$ con $g$ continua.
    Supponiamo che:
    1. $f \ge -T$, ovvero $f$ sia limitata dal basso
    2. $\exists x_n \rar +\infty, \exists y_n \rar -\infty : \lim_n f(x_n) = \lim_n f(y_n) = -T$ (questo succede sempre se $f$ è periodica)
       
    Allora il rilassato $\bar F(u) = (a-b)T + \int_a^b g(u, x) \de x$ e non si ha minimo a meno che il minimo di $\int_a^b g(u, x)$ esista e sia una spezzata con pendenze $m_i$ tali che $f(m_i) = -T$.

    *Dimostrazione*:
    1. Sappiamo che $\inf F(u) = \inf \bar F(u)$.
    2. Per calcolare il rilassato basta calcolare quello di $R(u) := \int_a^b f(\dot u)$ (infatti l'altro pezzo è continuo ed esce).
    3. Dico che $\bar R(u) = S(u) = \int_a^b -T = (a-b)T$. Per dimostrarlo utilizziamo la strategia 2
    4. $S(u)$ è SCI poiché è costante, e $S(u) \le R(u)$ poiché $f(x) \ge -T$.
    5. Consideriamo come denso in energia le funzioni affini a tratti (visto che $S$ è costante basta un denso qualunque).
       Approssimiamo ora una retta con una spezzata vicina in norma $\cL^2$ e con coefficienti angolari in $\lrg{x_n, y_n}_n$ in modo che $f(\dot u)$ sia molto vicino a $-T$ costantemente.
       Questo si può fare prendendo coefficienti angolari in modulo sempre più alti in modo che il limite della $f$ tenda a $-T$.
    6. Se ci fosse un minimo $u_0$ avrei $F(u_0) = \bar F(u_0) = (a-b)T + \int_a^b g(u_0, x) \de x$.
       Quindi $u_0$ dovrebbe essere un minimo di $g$, ovvero $g(u, x) \ge g(u_0, x)$.
       Se $g$ *non* ammette minimo, il problema non ha minimo ed ha inf $= (a-b)T + \inf \int_a^b g(u, x) \de x$.
       
       Supponiamo da ora che $g$ ammetta minimo $u_0$
    7. Sia $Q = \int_a^b g(u_0, x)$: allora per ogni altra funzione si ha $F(u) \ge Q + \int_a^b f(\dot u)$ ma la parte in $f$ ha minimo solo sulle spezzate con pendenze $m_i$ tali che $f(m_i) = -T$.
       Quindi si hanno i due casi:
       - *Esiste un minimo* se nella classe in cui vogliamo minimizzare esiste una spezzata di rette con coefficienti angolari in $f^{-1}(-T)$ tale che essa è anche un minimo di $\int_a^b g(u_0, x)$.
       - *Non esiste il minimo* se non vale la condizione di cui sopra. In questo caso l'inf è $(a-b)T + \inf \int_a^b g(u, x) \de x$ che si ottiene approssimando con spezzate di pendenze opportune l'inf di $g$.
* Gamma convergenza (pp. 128-146)
  Anche in questa sezione supponiamo $(\bbX, d)$ metrico. Dove compare $f_\infty$ e non è specificato si intende che esso è il $\Gamma-\liminf$ e se compare $f_\infty^+$ esso è il $\Gamma-\limsup$.
  - (*Definizione di \Gamma-convergenza*) Data $f_n: \bbX \rar \bar\bbR$ successione di funzioni, essa \Gamma-converge ad $f_\infty: \bbX \rar \bar\bbR$ se valgono:
    1. (*Liminf inequality*) $\forall x_n \rar x_\infty \in \bbX$ vale $\liminf_{n \rar +\infty} f_n(x_n) \ge f_\infty(x_\infty)$.
    2. (*Limsup inequality*) $\forall x \in \bbX$ $\exists x_n \rar x$ tale che $\limsup_{n \rar +\infty} f_n(x_n) \le f_\infty(x_\infty)$.
       In questa in realtà vale il limite.
  - (*Definizione di Recovery sequence*) Le successioni $x_n \rar x$ per cui vale la limsup inequality si dicono *recovery sequence* per $x$.
  - (*Rilassato come \Gamma-limite*) Se $f_n(x) = f(x) \quad \forall n$ allora $f_n \rar^\Gamma \bar f$.
  - (*Convergenza uniforme sui compatti e semicontinuità implica \Gamma-limite*) Supponiamo che $f_n \rar f_\infty$ unif sui compatti di $\bbX$ e che $f_\infty$ sia SCI.
    Allora $f_n \rar^\Gamma f_\infty$.
  - (*Unicità del \Gamma-limite*) Viene dal fatto che se esiste coincide con il $\Gamma-\liminf$ che ha una definizione come formula rispetto alle $f_n$.
  - (*Stabilità per perturbazioni continue*) Siano $f_n: \bbX \rar \bar\bbR$ e $g: \bbX \rar \bar\bbR$ continua.
    Allora $\Gamma-\lim_{n \rar +\infty} \lrq{f_n(x) + g(x)} = \lrq{\Gamma-\lim_{n \rar +\infty} f_n(x)} + g(x)$.

    *Osservazione 1*: Per la liminf inequality basta $g$ SCI e per la limsup inequality basta $g$ SCS.
    
    *Osservazione 2*: Ciò rimane vero se sostituisco $g$ fissa con una successione di funzioni continue $g_n \rar g_\infty$ uniformemente sui compatti.
  - (*$\Gamma-\liminf$ e $\Gamma-\limsup$*) Data $f_n : \bbX \rar \bar\bbR$ si possono sempre definire:
    1. $\Gamma-\liminf_n f_n(x) := \inf\lrg{\liminf_{n \rar +\infty} f_n(x_n) \mid x_n \rar x}$
    2. $\Gamma-\limsup_n f_n(x) := \inf\lrg{\limsup_{n \rar +\infty} f_n(x_n) \mid x_n \rar x}$

    Essi soddisfano $\Gamma-\liminf_n f_n \le \Gamma-\limsup_n f_n$ e coincidono se e solo se esiste il \Gamma-limite.
  - (*Lemma fondamentale per $\Gamma-\liminf$*) $\forall x \in \bbX, \forall i \in \bbN, \forall r, \epsilon > 0 \quad \exists j \in \bbN, \exists y \in \bbX$ tali che $j > i$, $d(x, y) \le r$, $f_j(y) \le \Gamma-\liminf_n f_n(x) + \epsilon$.
    Ovvero frequentemente c'è un punto vicino ad $x$ che è poco più basso del $\Gamma-\liminf$.
  - (*$\Gamma-\liminf$ di una sottosuccessione*) Sia $k_n \rar +\infty$ successione crescente di naturali e sia $x_n \rar x_\infty$.
    Allora $\liminf_{n \rar +\infty} f_{k_n}(x_n) \ge f_\infty(x_\infty)$ (ovvero è come dire che il $\Gamma-\liminf$ si una successione è $\ge$).
    La dimostrazione si fa "riempendo i buchi" con il valore costante $x_\infty$.
  - Nella definizione di $\Gamma-\liminf$ e di $\Gamma-\limsup$ gli $\inf$ sono in realtà dei minimi.
  - (*SCI di \Gamma-\liminf e \Gamma-\limsup*) $\Gamma-\liminf_n f_n(x)$ e $\Gamma-\limsup_n f_n(x)$ sono sempre funzioni SCI.
  - (*inf, liminf, \Gamma-liminf sugli aperti*) Sia $A \subseteq \bbX$ un aperto. Allora $\liminf_n \lrt{\inf_{x \in A} f_n(x)} \le \inf_{x \in A} \lrt{\Gamma-\liminf_n f_n(x)}$.
  - (*inf, liminf, \Gamma-liminf sui compatti*) Sia $K \subseteq \bbX$ un compatto. Allora $\liminf_n \lrt{\inf_{x \in K} f_n(x)} \ge \inf_{x \in K} \lrt{\Gamma-\liminf_n f_n(x)}$.
  - (*Equicoercività*) Una successione $f_n: \bbX \rar \bar\bbR$ si dice equicoerciva se $\exists K \subseteq \bbX$ compatto (indipendente da $n$) tale che $\forall n \in \bbN$ si abbia $\inf_{x \in \bbX} f_n(x) = \inf_{x \in K} f_n(x)$.
  - (*Convergenza dei minimi*) Sia $f_n: \bbX \rar \bar\bbR$ una successione di funzioni e $f_\infty$ il suo $\Gamma-\liminf$.
    Supponiamo inoltre che *$f_n$ sia equicoerciva* con compatto $K$.
    Allora vale che:
    1. $f_\infty$ ammette minimo in $\bbX$.
    2. $\liminf_n \lrt{\inf_{x \in \bbX} f_n(x)} = \min_{x \in \bbX} f_\infty(x)$.
    3. Se $f_\infty$ è anche \Gamma-limite allora se $\lrg{x_n} \subseteq \bbX$ è una successione di quasi-minimi, ovvero vale $\lim_n \lrt{f_n(x_n) - \inf_{x \in \bbX} f_n(x)} = 0$, ed una sua sottosuccessione converge, diciamo $x_{k_n} \rar x_\infty$, allora $x_\infty \in \argmin \lrg{f_\infty(x) \mid x \in \bbX}$.
    4. se $f_\infty$ è anche \Gamma-limite allora $\lim_n \lrt{\inf_{x \in \bbX} f_n(x)} = \min_{x \in \bbX} f_\infty(x)$.
  - (*Lemma fondamentale per il $\Gamma-\limsup$*) $\forall x \in \bbX, \forall r, \epsilon > 0$, $\exists i \in \bbN$ tale che $\forall j \ge i$ si ha $\exists y$ tale che $d(x, y) \le r$ e $f_j(y) \le \Gamma-\limsup_n f_n(x) + \epsilon$.
    Ovvero definitivamente c'è un punto vicino ad $x$ che è poco più basso del $\Gamma-\limsup$.
** TODO Vedere l'esempio di pagina 145 e generalizzare
* Tipologie di minimo e variazione seconda (pp. 147-169)
  - (*Definizioni di tipi di minimo*) Il setting è quello di un funzionale integrale $F(u)$ con DBC.
    1. *GM* (Global Minimum) Se $F(u) \ge F(u_0)$ per ogni $u \in \bbX$
    2. *WLM* (Weak Local Minimum) Se $u_0$ è un punto di minimo locale rispetto alla metrica $\cC^1$, ovvero $\exists r > 0$ tale che $F(u) \ge F(u_0)$ per ogni $u \in \bbX$ tale che $\norm{u - u_0}_\infty + \norm{\dot u - \dot u_0}_\infty \le r$.
    3. *SLM* (Strong Local Mimimum) Se è come sopra ma rispetto alla metrica $\cC^0$, ovvero se $\exists r > 0 \tc F(u) \ge F(u_0)$ per ogni $u \in \bbX$ tale che $\norm{u - u_0}_\infty \le r$
    4. *DLM* (Directional Local Minimum) Se la funzione $\phi(t) = F(u_0 + tv)$ ha minimo locale per $t = 0$ per ogni $v \in \cC^1$ nulla al bordo.
  - (*Implicazioni tra i minimi*) GM $\implies$ SLM $\implies$ WLM $\implies$ DLM. Tutte le implicazioni inverse *non valgono*.
  - (*Variazione Seconda*) Costruiamo $\psi(t) = F(u_0 + tv)$ e definiamo la variazione seconda del funzionale $\delta^2 F(u_0, v) = \psi''(0)$.
  - (*DLM $\implies \delta^2 \ge 0$*) Se $u_0$ è DLM allora $\delta^2 F(u_0, v) \ge 0 \quad \forall v \in \cC^1$ nulle al bordo, ammesso che esista.
    Inoltre, fissato $u_0$, $v \mapsto \delta F(u_0, v)$ è lineare e $v \mapsto \delta^2 F(u_0, v)$ è quadratica, analoga alla forma quadratica della matrice Hessiana.
** Funzionali quadratici ed implicazioni
   Il setting in cui ci mettiamo adesso è quello dei funzionali quadratici, ovvero cose del tipo $Q(v) := \int_a^b A(x) v^2 + 2 B(x) v \dot v + C(x) \dot v^2 \de x$.
   Sui coefficienti $A, B, C$ si possono dare varie ipotesi ($\cL^\infty$ è sufficiente per dare senso a $Q(v)$ per ogni $v \in H^1$).
   Noi considereremo sempre funzioni $v$ nulle al bordo.

   Nel seguito $L$ sta per Legendre, $J$ sta per Jacobi, $R$ sta per Riccati.

   - (*Funzionali non-negativi*) Un funzionale quadratico si dice non-negativo o semidefinito positivo se vale $\forall v \in V \quad Q(v) \ge 0$, dove è indifferente se $V$ è uno qualsiasi dei seguenti: $\cC^\infty_c, \cC^1, P\cC^1, H^1$ (tutte nulle al bordo).

     /Condizioni necessarie per non-negatività/: (L) + [(L^{+}) \implies (J)]
     
     *Nel dettaglio*: 
     1. Se $C$ è continuo, $A, B$ limitati allora vale (L).
     2. Se i coefficienti sono $\cC^1$ allora (L^{+}) $\implies$ (J).

     /Condizioni sufficienti per non-negatività/: (L^{+}) + (J^{+})

     *Nel dettaglio* si ha (L^{+}) + (J^{+}) \implies (J^{++}) \implies (R) \implies $Q \ge 0$.
     
     /Condizione mega-sufficiente/: Se vale $A(x) C(x) \ge [B(x)]^2$ e $C(x) \ge 0$ per ogni $x \in [a, b]$, allora $Q(v) \ge 0$ per ogni $v \in \cC^\infty$ anche senza supporto compatto.

   - (*JDE*) Si intende $(C \dot v + B v)' = A v + B \dot v$ che è (ELE) di $Q(v)$.
     Se i coefficienti sono di classe $\cC^1$ e vale (L^{+}) posso fare i conti e portare in forma normale ottenendo l'equazione $\ddot v = - \frac{\dot C}{C} \dot v + \frac{A - \dot B}{C} v$.
     A questo punto valgono tutti i teoremi (esistenza, regolarità, unicità) di Analisi 2.
   - (*Punti coniugati*) Un punto $c$ si dice punto coniugato di $a$ (estremo dell'intervallo) se la soluzione del problema di Cauchy (JDE) con $u(a) = 0, \dot u(a) = 1$ si annulla in $c$.
     (La condizione $\dot u(a) = \alpha \neq 0$ porterebbe ad un multiplo della stessa soluzione e la definizione di punto coniugato non dipende da ciò).

     Allo stesso modo si definiscono punti coniugati di $b$ risolvendo (JDE) con $u(b) = 0, \dot u(b) = 1$.
   - (*Reciprocità dei punti coniugati*) Sotto l'ipotesi (L^{+}) sono equivalenti:
     1. (J), ovvero Non esistono punti coniugati di $a$ nell'intervallo $(a, b)$
     2. Non esistono punti coniugati di *$b$* nell'intervallo $(a, b)$
     3. L'unica soluzione di (JDE) che si annulla almeno due volte nell'intervallo $(a, b)$ è quella identicamente nulla
   - (*Lemma di oscillazione*) Data un'equazione lineare del tipo $\ddot w = \alpha(x) \dot w + \beta(x) w$. Siano $w_1, w_2$ due soluzioni non identicamente nulle e non una multipla dell'altra.
     Allora tra ogni coppia di zeri di $w_1$ esiste uno zero (e quindi anche uno solo) di $w_2$.
   - (*Stima dall'alto per funzionali quadratici*) $\abs{Q(v)} \le M \int_a^b \dot v^2(x) \de x$ per ogni $v \in \cC^\infty_c(a, b)$.
     Dove $M$ dipende dalle norme infinito di $A, B, C$ e diventa piccolo a piacere quando le norme diventano piccole.
     In particolare $M = (\norm{C}_\infty + \norm{B}_\infty) + (\norm{A}_\infty + \norm{B}_\infty) (b - a)^2$.
   - (*Stima dal basso per un funzionale quadratico*) Sia $Q(v)$ un funzionale quadratico che soddisfa (L^{+}) e (J^{+}). Allora esiste $\epsilon_0 > 0$ tale che $Q(v) \ge \epsilon_0 \int_a^b \dot v(x)^2 \de x$ per ogni $v \in \cC^\infty_c(a, b)$.
   - (*Funzionali non-negativi vicini*) Sia $Q_0(v)$ funzionale quadratico con coefficienti $A_0, B_0, C_0$ che soddisfa $(L^+), (J^+)$.
     Sia $Q(v)$ un funzionale quadratico con coefficienti $A, B, C$ vicini in norma $\cC^0$ ad $A_0, B_0, C_0$.
     Se $\norm{A - A_0}_\cC^0, \norm{B - B_0}_\cC^0, \norm{C - C_0}_\cC^0$ sono abbastanza piccole, allora $Q(v) \ge 0$ per ogni $v \in \cC^\infty_c$.
*** Diagramma delle implicazioni
   Legenda per leggere il diagramma seguente:
   - (E) :: $u_0$ soddisfa (ELE).
   - (L) :: $C(x) \ge 0$ per ogni $x \in [a, b]$.
   - (L^{+}) :: $C(x) > 0$ per ogni $x \in [a, b]$ (se $C(x)$ è continuo è equivalente a dire $C(x) \ge m > 0$).
   - (J) :: Non esistono punti coniugati di $a$ nell'intervallo $(a, b)$.
   - (J^{+}) :: Non esistono punti coniugati di $a$ nell'intervallo $(a, b]$, ovvero (J^{+}) = (J) + $b$ non è pto coniugato.
   - (J^{++}) :: Esiste una soluzione $w$ di (JDE) tale che $w(x) > 0$ per ogni $x \in [a, b]$.
   - (R) :: Esiste $z: [a, b] \rar \bbR$ $\cC^1$ tale che (RDE): $\dot z = \frac{[z + B]^2}{C} - A$ per ogni $x \in [a, b]$.
   - (W) :: $E(x, u_0(x), \dot u_0(x), q) \ge 0 \quad \forall x \in [a, b], \forall q \in \bbR$ (vedere in Calibrazioni per l'Eccesso di Weierstrass)
   - (W^{+}) :: $\exists \delta > 0$ tale che $E(x, s, p, q) \ge 0$ $\forall x \in [a, b], \forall q \in \bbR, \forall (s, p) \in \bbR^2$ tali che $\abs{s - u_0(x)} \le \delta$ e $\abs{p - u_0(x)} \le \delta$.
   - (F) :: Field: Esistenza di un campo di Weierstrass
   - (WRF) :: Weierstrass representation formula

   \begin{array}{ccccccc}
      &          & (E) + (L^+) + (J^+) + (W^+) &          & (E) + (L^+) + (J^+) &          &                                  \\
      &          & \Downarrow                  &          & \Downarrow          &          &                                  \\
   GM & \implies & SLM                         & \implies & WLM                 & \implies & DLM                              \\
      &          & \Downarrow                  &          &                     &          & \Downarrow                       \\
      &          & (W)                         &          &                     &          & (E) + (L) + [(L^+) \implies (J)] \\
   \end{array}
   
   \begin{align*}
   (L^+) + (J^+) \implies (J^{++}) \implies (R) \implies Q \ge 0 \\
   (E) + (L^+) + (J^+) \implies (F) \implies (WRF) \\
   (W) + (WRF) \implies SLM \\
   L \text{ convessa in } p \implies (W) \\
   \end{align*}

** TODO Inserire esempi di non valgono le implicazioni inverse p. 148 (Magari tornano utili negli esercizi)
* Calibrazioni (pp. 170-193)
  - (*Null lagrangian*) Sono lagrangiane del tipo $\hat L(x, s, p) = A(x, s) p + B(x, s)$ con $A, B \cC^1$ e verificano $A_x(x, s) = B_s(x, s)$.
    Per teoremi di analisi due vale, sotto ipotesi di semplice connessione della zona di definizione, che esiste $V(x, s)$ tale che $A(x, s) = V_s(x, s)$ e $B(x, s) = V_x(x, s)$.
  - (*Calibrazione via null lagrangian*) Consideriamo un problema di minimo con DBC e lagrangiana $L(x, s, p)$ e sia $u_0: [a, b] \rar \bbR$ un candidato punto di minimo.
    Supponiamo che
    1. Esista $\hat L(x, s, p) = A(x, s) p + B(x, s)$ null lagrangian (ovvero $A_x(x, s) = B_s(x, s)$)
    2. Valga $L(x, s, p) \ge \hat L(x, s, p)$ $\forall (x, s, p) \in [a, b] \times \bbR^2$
    3. Valga $L(x, u_0(x), \dot u_0(x)) = \hat L(x, u_0(x), \dot u_0(x)) \quad \forall x \in [a, b]$

    Allora $u_0(x)$ è punto di minimo.
    Inoltre i punti di minimo sono tutti e soli quelli che verificano l'uguaglianza $L(x, v_0(x), \dot v_0(x)) = \hat L(x, v_0(x), \dot v_0(x))$ per ogni $x \in [a, b]$.
  - (*Osservazioni sulla generalità*) Sia quando $L$ è quadratica, sia quando $L$ è convessa in $(s, p)$ si possono riottenere i teoremi che avevamo precedentemente.
  - (*Value function*) Consideriamo il problema di minimo $V(x, s) := \min \lrg{\int_a^x L(t, u(t), \dot u(t)) \de t \mid u(a) = A, u(x) = S, u \in \cC^1[a, x]}$, e voglio trovare $V(b, B)$ per risolvere un problema di minimo classico.
  - (*Calibrazione via Value Function*) Supponiamo che $V(x, s)$ sia di classe $\cC^1$ (questo è da controllare, non è per nulla scontato).
    Allora $\hat L(x, s, p) = V_s(x, s) p + V_x(x, s)$ verifica le ipotesi del teorema di calibrazione.

    *Botta di culo infinita*: Se sono così bravo da guessare il punto di minimo per ogni soluzione finale $u(x) = s$, posso calcolare quello che dovrebbe essere $V(x, s)$ e verificare a mano che soddisfa la disuguaglianza (b) e l'uguaglianza (c) nel teorema di calibrazione.
  - (*Eccesso di Weierstrass*) Data una lagrangiana $L(x, s, p)$ definiamo eccesso di Weierstrass come $E(x, s, p, q) = L(x, s, q) - L(x, s, p) - (q - p) L_p(x, s, p)$.
    È una specie di differenza tra $L$ ed il suo sviluppo al primo ordine in $p$.

    Se $L$ è convessa in $p$ allora $E \ge 0$.
  - (*Campo di Weierstrass (F)*) Si dice che un funzionale ha un campo di Weierstrass se $\exists \epsilon_0 > 0$ ed $\exists u: [-\epsilon_0, \epsilon_0] \times [a, b] \rar \bbR$ tale che:
    1. $u(0, x) = u_0(x)$ per ogni $x \in [a, b]$
    2. Per ogni $\epsilon \in [-\epsilon_0, \epsilon_0]$ la funzione $x \mapsto u(\epsilon, x)$ risolve (ELE)
    3. Per ogni $x \in [a, b]$, la funzione $\epsilon \mapsto u(\epsilon, x)$ è strettamente crescente

    /Brutalmente/: $u_0(x)$ è immersa in una famiglia di soluzioni di (ELE), ovviamente con DBC diverse.
  - (*Slope function*) Dato un campo di Weierstrass si definisce la sua slope function $p : \Omega \rar \bbR$ nel seguente modo: dato $(x, s)$ si prende $\epsilon \in [-\epsilon_0, \epsilon_0]$ tale che $u(\epsilon, x) = s$ e poi si pone $p(x, s) = u_x(\epsilon, x)$.
    La slope function soddisfa l'equazione $p(x, u(\epsilon, x)) = u_x(\epsilon, x) \quad \forall (\epsilon, x) \in [-\epsilon_0, \epsilon_0] \times [a, b]$.
    
    In particolare se risolvo $\dot u = p(x, u)$ trovo proprio le funzioni $u(\epsilon, x)$.
  - (*Riscrittura di (ELE) con slope function*) $L_{px} + L_{ps} p + L_{pp} (p_x + p_s p) = L_s$.
  - (*Weierstrass representation formula (WRF)*) Sia $v: [a, b] \rar \bbR$ di classe $\cC^1$ con le stesse DBC di $u_0(x)$.
    Allora $F(v) - F(u_0) = \int_a^b E(x, v(x), p(x, v(x)), \dot v(x)) \de x$, dove $E(x, s, p, q) = L(x, s, q) - L(x, s, p) - (q - p) L_p(x, s, p)$.
* Spazi con nozione di convergenza
  - (*Definizione*) Dato un insieme $\bbX$, una nozione di convergenza in $\bbX$ significa dichiarare le successioni convergenti ed i relativi limiti, ovvero significa dare un sottoinsieme di $\Seq(\bbX) \times \bbX$.
  - (*Compattezza*) $K \subseteq \bbX$ si dice compatto per successioni se $\forall \lrq{x_n}_n \subseteq K$, $\exists x_\infty \in K \tc x_n \rar x_\infty$.
  - (*Continuità*) $f: \bbX \rar \bbR$ si dice continua se per ogni successione $x_n \rar x_\infty$ in $\bbX$ vale $f(x_n) \rar f(x_\infty)$.
  - (*SCI*) $f: \bbX \rar \bbR$ si dice SCI se per ogni successione $x_n \rar x_\infty$ in $\bbX$ vale $\liminf_{n \rar +\infty} f(x_n) \ge f(x_\infty)$.
  - (*Teorema di Weierstrass*) Data $f: \bbX \rar \bbR$ SCI con $\bbX$ compatto $\implies f$ ha minimo su $\bbX$.
  - (*Coercività*) $f: \bbX \rar \bbR$ si dice coerciva se $\exists K \subseteq \bbX$ tale che $\inf_{x \in \bbX} f(x) = \inf_{x \in K} f(x)$.
    
    In particolare se $f: \bbX \rar \bbR$ è SCI ed esiste un sottolivello non vuoto e contenuto in un compatto allora $f$ ammette minimo.
* Spazi di Hilbert e convergenza Debole
  - (*Formule con componenti*) $\norm{v}^2 = \sum_{n=1}^\infty \scal{v, e_n}^2$ e si ha $\scal{v, w} = \sum_{n=1}^\infty \scal{v, e_n} \scal{w, e_n}$.
  - (*Convergenza di serie*) Data $\lrg{e_n}$ una basa Hilbertiana di $\cH$ (sistema ortonormale a span denso) e $\lrg{v_n}$ una successione di numeri reali si ha
    $$\sum_{n=1}^\infty v_n e_n \text{ converge in } \cH \sse \sum_{n=1}^\infty v_n^2 \text{ converge in } \bbR$$
  - (*Palle non fortemente compatte*) Se $\cH$ ha dimensione infinita, allora le palle *NON* sono compatte.
  - (*Convergenza forte e debole*): $x_n \rar x_\infty$ è la convergenza forte, ovvero $\norm{x_n - x_\infty} \rar 0$ come numeri reali.
    La convergenza debole si indica con $x_n \rhu x_\infty$ e significa che $\forall v \in \cH \quad \scal{x_n, v} \rar \scal{x_\infty, v}$ come numeri reali.

    Ovviamente convergenza forte implica convergenza debole.
  - (*Continuità forte della norma*) Se $x_n \rar x_\infty$ allora $\norm{x_n} \rar \norm{x_\infty}$. Purtroppo la norma *non* è debolmente continua.
  - (*Semicontinuità debole della norma*) Se $x_n \rhu x_\infty$ allora $\liminf_{n \rar +\infty} \norm{x_n} \ge \norm{x_\infty}$.
  - (*Compattezza debole delle palle*) In un Hilbert separabile le palle chiuse sono debolmente compatte.
    Ovvero data una successione $\lrg{v_n} \subseteq \cH \tc \norm{v_n}^2 \le M$, esiste una sottosuccessione $v_{n_k} \rhu v_\infty$.
  - (*Convergenza dei prodotti scalari*) Se $v_n \rhu v_\infty$ e $w_n \rar w_\infty$ allora $\scal{v_n, w_n} \rar \scal{v_\infty, w_\infty}$.
    Entrambe convergenze deboli non sono sufficienti.
  - (*Indebolimento convergenza debole*) Se $\lrg{v_n} \subseteq \cH$ è limitata, $W \subseteq \cH$ un sottoinsieme a span denso rispetto alla convergenza forte (ad esempio una base hilbertiana) e vale $\scal{v_n, w} \rar \scal{v_\infty, w} \quad \forall w \in W$ allora $v_n \rhu v_\infty$.
  - (*Limitatezza delle successioni convergenti*) Se $v_n \rhu v_\infty$ allora $v_n$ è limitata.
* Spazi di Sobolev e derivata Debole
  - (*Definizione W*) Sia $p \ge 1$. Si dice che $u \in W^{1,p}(a, b)$ e che $v$ è la sua derivata debole se $u, v \in \cL^p(a, b)$ e vale la formula $\forall \phi \in \cC^\infty_c(a, b) \quad \int_a^b u(x) \dot\phi(x) \de x = - \int_a^b v(x) \phi(x) \de x$.
  - (*Definizione H*) Sia $p \ge 1$. Si dice che $u \in H^{1,p}(a, b)$ e che $v$ è la sua derivata debole se $u, v \in \cL^p(a, b)$ ed $\exists \lrg{u_n}_n \subseteq \cC^1(a, b)$ tali che $u_n \rar^{\cL^p} u$ e $u_n' \rar^{\cL^p} v$.
  - (*Completamento delle $\cC^1$*) $H^{1, p}$ è anche il completamento delle funzioni $\cC^1$ dotate della metrica $d(f, g) = \norm{f - g}_{\cL^p} + \norm{f' - g'}_{\cL^p}$.
  - (*Derivata convergente in $\cL^p$*) $W^{1,p}$ si può anche definire come funzioni $u$ tali che il rapporto incrementale $R_h(x) = \frac{u(x+h) - u(x)}{h}$ converge a qualcosa in $\cL^p$. Tale qualcosa sarà la derivata debole.
  - (*Unicità della derivata debole*) Se la derivata debole esiste, è unica.
  - (*Consistenza con il caso classico*) $u \in \cC^1(a, b) \implies u \in W^{1,p}(a, b)$ e la derivata vera coincide con quella debole.
    In realtà si può vedere che ci stanno anche tutte le funzioni $P\cC^1$ (ovvero $\cC^1$ a tratti).

    Inoltre, se $u \in W^{1,p}$ e la sua derivata debole $v$ è continua, allora $u \in \cC^1$.
  - Sia $\lrg{u_n}_n \subseteq W^{1,2}$ e supponiamo che $u_n \rhu^{\cL^2} u_\infty$ e $\dot u_n \rhu^{\cL^2} v_\infty$. Allora $u_\infty \in W^{1,2}$ e $v_\infty = \dot u_\infty$.
  - (*Primitive della derivata debole*) Sia $u \in W^{1,p}(a, b)$ con $v = \dot u$. Allora si ha $u(x) = c + \int_a^x v(t) \de t$.
  - (*Hölderianità delle funzioni di Sobolev*) /Nota: Questo è vero solo in dimensione uno/. Sia $p > 1$ e $q = p'$ l'esponente coniugato, $u \in W^{1,p}(a,b)$. Allora $u \in \cC^{0,\frac{1}{q}}$, in particolare $u$ è continua.
    Inoltre $\abs{u(y) - u(x)} \le \norm{\dot u}_{\cL^p} \cdot \abs{y - x}^{\frac{1}{q}}$.
* Teoremi di Analisi inferiore
  Riportiamo qui alcuni lemmini che servono nel corso ma che si dovrebbero già sapere:
  - *Integrali dipendenti da parametro*: $[a,b] \subseteq \bbR$, $\delta > 0$ e $f: [a,b] \times (-\delta, \delta) \rar \bbR$ e poniamo $\psi(t) = \int_a^b f(x, t) \de x$.
    1. Se $f(x, t)$ è continua in $[a,b] \times (-\delta, \delta)$ si ha che $\psi(t) è continua in $(-\delta, \delta)$
    2. Se $f_t(x, t)$ è continua in $[a,b] \times (-\delta, \delta)$ allora $\psi$ è derivabile e vale $\psi'(t) = \int_a^b f_t(x, t) \de x$
  - *Beppo Levi o Convergenza Monotona*: Siano $f_n: (a, b) \rar \bbR$ misurabili secondo lebesgue tali che $f_n \ge 0$ e $f_{n+1} \ge f_{n}$.
    Allora $\int_a^b \sup_n f_n(x) \de x = \sup_n \int_a^b f_n(x) \de x$.
  - *Lemma di Fatou*: Siano $f_n: (a, b) \rar \bbR$ misurabili secondo lebesgue e $f_n \ge 0$.
    Allora $\int_a^b \liminf_{n \rar \infty} f_n(x) \de x \le \liminf_{n \rar \infty} \int_a^b f_n(x) \de x$.
  - *Convergenza Dominata*: Siano $f_n: (a, b) \rar \bbR$ misurabili secondo lebesgue, convergenti puntualmente ($\forall x : f_n(x) \rar f_\infty(x)$) e dominate da una funzione integrabile $g: (a, b) \rar \bbR$ ($\abs{f_n(x)} \le g(x)$).
    Allora $\int_a^b f_\infty(x) \de x = \lim_{n \rar \infty} \int_a^b f_n(x) \de x$.
  - *Disuguaglianza di Hölder*: Dati $r, p_i \ge 1$ tali che $\sum_i \frac{1}{p_i} = \frac{1}{r}$ ed $f_i \in \cL^{p_i}$ si ha $\prod_i f_i \in \cL^r$ e vale $\norm{\prod_i f_i}_{\cL^r} \le \prod_i \norm{f_i}_{\cL^{p_i}}$.
  - *Teorema di Approssimazione di $\cL^p$*: $p \ge 1$ ed $f \in \cL^p(a, b)$. Allora esiste una successione $\lrg{f_n} \subseteq \cC^0(a,b)$ tale che $f_n \rar^{\cL^p} f$ e $f_n \rar f$ in maniera puntualmente dominata in $\cL^p$.
  - *Ascoli-Arzelà*: Siano $\bbX, \bbY$ spazi metrici ed $f_n: \bbX \rar \bbY$ e supponiamo che:
    1. (Compattezza ad $x$ fisso): $\forall x \in \bbX : \exists K_x \subseteq \bbY \text{ cpt} \tc f_n(x) \in K_x \quad \forall n \in \bbN$
    2. (Equi-continuità): $\forall \epsilon > 0 \quad \forall x \in [a,b] \quad \exists \delta > 0 \tc y \in [a,b] \cap (x-\delta, x+\delta) \implies \abs{f_n(x) - f_n(y)} \le \epsilon \quad \forall n \in \bbN$

    Allora se $\bbX$ è compatto esiste $f_{n_k} \rar f_\infty$ uniformemente in $\bbX$.
    Se $\bbX$ è unione numerabile di compatti si ha invece convergenza uniforme sui compatti.

* Fatti elementari ma che si scordano
  - (*superadditività del liminf*) $\liminf_n (A_n + B_n) \ge \liminf_n A_n + \liminf_n B_n$. Se una delle due ha limite allora vale l'uguale.
  - (*subadditività del limsup*) $\limsup_n (A_n + B_n) \le \limsup_n A_n + \limsup_n B_n$. Se una delle due ha limite allora vale l'uguale.
  - (*Equazioni di Riccati*) Sono equazioni differenziali del tipo $\dot z = a(x) z^2 + b(x) z + c(x)$.
    C'è un legame generale tra le equazioni di Riccati e le equazioni lineari di ordine due del tipo $\ddot w = \alpha(x) \dot w + \beta(x) w$.
    Il legame è dato dalla ricerca di soluzioni positive dell'equazione al secondo ordine del tipo $w(x) = e^{-v(x)}$.
    Data una di queste e posto $z(x) = \dot v(x)$ essa risolve una riccati del tipo $\dot z = z^2 + \alpha(x) z + \beta(x)$.
