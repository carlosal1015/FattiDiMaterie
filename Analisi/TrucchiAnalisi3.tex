\documentclass[a4paper,NoNotes,GeneralMath]{stdmdoc}

\newcommand{\intpie}{\int_{-\pi}^\pi }
\newcommand{\fracpie}{\frac{1}{\pi}}
\newcommand{\fractopie}{\frac{1}{2\pi}}
\newcommand{\CT}[1]{\cC^{#1}(\bbT)}
\newcommand{\LT}[1]{\cL^{#1}(\bbT)}
\newcommand{\cl}{\ell}
\newcommand{\Lincont}{\text{Lincont }}
\newcommand{\codim}{\text{codim }}
\DeclareMathOperator{\supess}{supess}

\begin{document}
	\title{Trucchi di Analisi 3}
	Questo file cerca di raccogliere alcuni teoremi, con dimostrazione, molto utili (non solo in Analisi 3). In particolare sono state esplicitate tecniche che si è viste utilizzare più volte negli esami.
	
	\section*{Teoremi di Convergenza Integrale}
	\subsection*{Convergenza Monotona}
	Sia $(X, \Sigma, \mu)$ uno spazio di misura. Siano inoltre $f_0, f_1, f_2, \ldots$ una sequenza non decrescente di funzioni $\Sigma$-misurabili e positive, ovvero $\forall k \in \bbN$ si ha $0 \le f_k \le f_{k + 1}$ quasi ovunque. \\
	Allora possiamo definire quasi ovunque il limite $f = \supess_{k \in \bbN} f_k$ e si ha che $f$ è $\Sigma$-misurabile e vale inoltre che
	$$ \lim_{k \rar \infty} \int_X f_k \de \mu = \int_X f $$
	dove l'integrazione è alla Lebesgue.
	
	\subsubsection*{Dimostrazione}
	Per induzione si può mostrare che per $n \le m$ si ha che $f_n \le f_m$ quasi ovunque. Allora sull'intersezione degli insiemi dove vale $f_k \le f_{k + 1}$ si può definire $f$ prendendo il $\sup$ delle $f_k$. Il complementare è ovviamente di misura nulla. \\
	Mostriamo ora che $f$ è misurabile: l'insieme $F_a = \{ f \ge a \}$ (in notazione da probabilisti) è l'unione degli insiemi $E_{k, a} = \{ f_k \ge a \} \cap \{ f_{k + 1} - f_k \ge 0 \}$ che sono quindi misurabili. Chiamiamo $E = \cap_{k \in \bbN} \{ f_{k + 1} - f_k \ge 0 \}$ \\
	Ovviamente $ \int_X f \ge \int_X f_k \quad \forall k \in \bbN $, per la monotonia dell'integrale (eventualmente spezzando sull'insieme dove non vale $f \ge f_k$, che però ha misura nulla). Allora, passando al limite (che esiste per monotonia) si ha $ \int_X f \ge \lim_{k \rar \infty} \int_X f_k$. \\
	Per la disuguaglianza opposta consideriamo una sequenza non decrescente di funzioni semplici positive $g_k$ tali che $g_k \le f$ e che $ \lim_k \int_X g_k \de \mu = \int_X f \de \mu$ che esiste per definizione di integrale. Basta ora dimostrare che $\forall k \in \bbN$ si ha $\int_X g_k \de \mu \le \lim_j \int_X f_j \de \mu$. \\
	Sia $c \in (0, 1)$, si fissi $k \in \bbN$ e siano $E_r = \{ f_r \le c g_k \} \cap E$. Allora si ha $L = \cap_{r \in \bbN} E_r$ ha misura nulla (altrimenti si avrebbe che $f_s \mid_L \le c g_k \quad \forall s$ e quindi anche $\sup_s f_s \mid_L \le c g_k < f$ assurdo). Inoltre $E_{r + 1} \subseteq E_r$, ovvero $\mu(E_{r + 1}) \le \mu(E_r)$. Quindi si ha che
	$$ \int_X c g_k \de \mu \le \int_X f_s \de \mu + \int_X c g_k \chi_{E_s} \de \mu $$
	Ora, prima di tutto si ha che, a $k$ fissato, facendo il limite in $s$, $\abs{\int_X c g_k \chi_{E_s} \de \mu} \le \mu(E_s) \max(g_k)$ ed il massimo di $g_k$ esiste perché $g_k$ è semplice. Allora si ha che il limite in $s$ di $\mu(E_s)$ tende a zero (per monotonia degli insiemi). A questo punto abbiamo la disuguaglianza
	$$ \int_X c g_k \de \mu \le \lim_{s \rar \infty} \int_X f_s \de \mu $$
	Ora facendo prima il limite per $c \rar 1$ (visto che la disuguaglianza vale per $c \in (0, 1)$) e successivamente prendendo il limite in $k$ si ha che
	$$ \int_X f \de \mu = \lim_{k \rar \infty} \int_X g_k \de \mu \le \lim_{s \rar \infty} \int_X f_s \de \mu $$
	che era la nostra tesi originaria.
	
	\subsection*{Lemma di Fatou}
	Sia $(X, \Sigma, \mu)$ uno spazio di misura. Siano inoltre $f_0, f_1, f_2, \ldots$ una sequenza di funzioni $\Sigma$-misurabili e positive q.o. Definiamo $f(x) = \liminf_{n \rar \infty} f_n(x)$ quasi ovunque. Allora $f$ è misurabile e si ha $\int_X f \de \mu \le \liminf_{n \rar \infty} \int_X f_n \de \mu$
	
	\subsubsection*{Dimostrazione}
	Lo dimostriamo usando convergenza monotona: Definiamo le funzioni $g_k = \inf_{n \ge k} f_n$ q.o. Allora la sequenza $g_0, g_1, \ldots$ è non decrescente e positiva di funzioni misurabili e converge puntualmente q.o. a $f = \liminf_{n \rar \infty} f_n$. \\
	Per ogni $k \le n$ si ha $g_k \le f_n$ e per monotonia dell'integrale che $\int_X g_k \de \mu \le \int_X f_n \de \mu$ e quindi segue che $\int_X g_k \de \mu \le \inf_{n \ge k} \int_X f_n \de \mu$. \\
	Usando il teorema di convergenza monotona segue che $$\int_X f \de \mu = \lim_{k \rar \infty} \int_X g_k \de \mu \le \newline
	\lim_{k \rar \infty} \inf_{n \ge k} \int_X f_n \de \mu = \liminf_{n \rar \infty} \int_X f_n \de \mu$$
	
	\subsection*{Convergenza Dominata}
	Sia $(X, \Sigma, \mu)$ uno spazio di misura. Siano inoltre $f_0, f_1, f_2, \ldots$ una sequenza di funzioni $\Sigma$-misurabili, tutte dominate da una funzione integrabile $g$, ovvero $\abs{f_n} \le g$ quasi ovunque. Se la sequenza di funzioni converge puntualmente quasi ovunque (ovvero per quasi ogni $x$ si ha $\exists \lim_{n \rar \infty} f_n(x)$) allora le $f_n$ sono integrabili, e si può definire quasi ovunque la funzione $f = \lim_{n \rar \infty} f_n$ e si ha che $\lim_{n \rar \infty} \int_X f_n \de \mu = \int_X f \de \mu$. (Per $g$ integrabile si intende $\int_X \abs{g} \de \mu < \infty$
	
	\subsubsection*{Dimostrazione}
	Notiamo che $\abs{f - f_n} \le \abs{f} + \abs{f_n} \le 2 g$ q.o. Inoltre sappiamo che, per ipotesi $\limsup_{n \rar \infty} \abs{f - f_n} = 0$ q.o. Usando ora la linearità e la monotonia dell'integrale si ha che:
	$$ \abs{\int_X f \de \mu - \int_X f_n \de \mu} = \abs{\int_X (f - f_n) \de \mu} \le \int_X \abs{f - f_n} \de \mu $$
	Usando il lemma di Fatou "inverso" (ovvero quello con i limsup, che discende banalmente da quello con i liminf) si ha che
	$$ \limsup_{n \rar \infty} \int_X \abs{f - f_n} \de \mu \le \int_X \limsup{n \rar \infty} \abs{f - f_n} \de \mu = 0 $$
	(dove abbiamo usato che $\abs{f - f_n}$ sia limitata da una funzione integrabile). Ciò implica che il limite esiste ed è
	$$ \lim_{n \rar \infty} \int_X \abs{f - f_n} \de \mu = 0 $$
	Ora togliendo il valore assoluto e per linearità si ottiene la tesi.
	
	\section*{Stime sugli $\cL^p$}
	\subsection*{Inclusione degli $\cL^p$ sui limitati}
	Se $\mu(\Omega) < \infty$ allora si ha che per $1 \le p \le q \le \infty$, $\cL^q \subseteq \cL^p$. \\
	Infatti, $\forall x \in \bbR$ (o anche in $\bbC$) si ha $\abs{x}^p \le 1 + \abs{x}^q$ (basta dividere in casi a seconda se $x < 1$ oppure $x \ge 1$). E quindi $\norm{f}_{\cL^p} = \int_\Omega \abs{f(x)}^p \de x \le \int_\Omega 1 \de x + \int_\Omega \abs{f(x)}^q \de x = \newline \mu(\Omega) + \norm{f}_{\cL^q} < \infty$ se $f \in \cL^q$, da cui $f \in \cL^p$.
	
	%\subsection*{Densità delle $\cC^\infty$}
	%Sia $f \in \cL^1$ e si prenda una sequenza di mollificatori $\Psi_n$. Allora si ha che
	%$$ \norm{\Psi_n \star f}_{\cL^1} \le \norm{\Psi_n}_{\cL^1} \norm{f}_{\cL^1} $$
	%ma adesso le $\Psi_n \star f$ sono $\cC^\infty$ perché posso scaricare le derivate sulla $\Psi_n$
	
	\subsection*{Continuità Integrale}
	Supponiamo che $f \in \cL^1(a, b)$ (prolungata per periodicità fuori). Allora si ha che $\lim_{h \rar 0} \int_a^b \abs{f(t + h) - f(t)} \de t = 0$.
	
	\subsubsection*{Dimostrazione}
	Per densità delle $\cC^\infty$ in $\cL^1$ posso prendere una sequenza di funzioni $f_n \in \cC^\infty$ che tendono ad $f$. Allora si ha che
	$$ \int_a^b \abs{f(t + h) - f(t)} \de t \le \int_a^b \abs{f(t + h) - f_n(t + h)} \de t + \int_a^b \abs{f_n(t + h) - f_n(t)} \de t + \int_a^b \abs{f_n(t) - f(t)} \de t $$
	Ora il primo e l'ultimo termine si stimano dicendo che $\lim_n \abs{f(t) - f_n(t)} = 0$ ed inoltre si ha che, considerando gli opportuni mollificatori, si ha $\abs{f - f_n} \le 3 \abs{f}$ ovvero sono limitate. Applicando quindi convergenza dominata essi tendono a zero in $n$. \\
	Rimane da stimare $\lim_{h \rar 0} \lim_{n \rar infty} \int_a^b \abs{f_n(t + h) - f_n(t)} \de t$
	
	% TODO: Il teorema della media integrale
	
	\section*{Equazioni Differenziali Classiche}
	\subsection*{Equazione della Corda Vibrante}
	L'Equazione della corda vibrante è $u_{tt} = c^2 u_{xx}$. Ci interessa capire per quali condizioni iniziali $u(0, x) = f(x)$ la soluzione esiste e se è unica. \\
	
	\subsubsection*{Separazione delle variabili}
	Notiamo che l'equazione è lineare in $u$, quindi la somma di soluzioni è soluzione. Proviamo separando le variabili, ovvero cerchiamo soluzioni della forma $u(t, x) = T(t) X(x)$. Allora si ha $T''(t) X(x) = c^2 T(t) X''(x)$ e quindi $\frac{T''(t)}{T(t)} = c^2 \frac{X''(x)}{X(x)} = - \lambda$ poiché sono due funzioni di varibili diverse che devono essere uguali, allora sono costanti. \\
	D'ora in poi mettiamo $c = 1$, dobbiamo quindi risolvere $X''(x) + \lambda X(x) = 0$, sapendo che $X(-\pi) = X(\pi) = 0$ (poiché la corda è fissata alle estremità). Mostriamo prima che $\lambda > 0$: si ha $X'' X + \lambda X^2 = 0 \implies \int X'' X + \lambda \int X^2 = 0$ e, integrando per parti si ha $- \int {X'}^2 + \lambda \int X^2 = 0$ da cui $\lambda$ è rapporto di due numeri positivi. \\
	Allora l'equazione ha come soluzioni $X(x) = c_1 \sin(\sqrt{\lambda} x) + c_2 \cos(\sqrt{\lambda} x)$. Inoltre, per soddisfare le condizioni iniziali otteniamo $X(x) = c_1 \sin(\sqrt{\lambda} x)$ e, affinché si abbia $\sin(\sqrt{\lambda} \pi) = 0$ deve essere $\lambda = k^2$, con $k \in \bbZ$. \\
	Otteniamo quindi le funzioni $\sin(nx)\cos(cnt)$ che soddisfano l'equazione e quindi ogni loro somma soddisfa.
	
	\subsubsection*{Serie di Fourier}
	% Da controllare se è vero che la soluzione si esprime come sua serie di Fourier con le ipotesi fornite
	Supponiamo che la soluzione sia esprimibile come la sua serie di Fourier (cosa che sappiamo essere vera se $u \in \cC^1 \cap \cL^1$), ovvero $u(t, x) = \sum_{n \in \bbZ} c_n(t) e^{inx}$. Allora, sostituendo nell'equazione si ha:
	$$ \sum_{n \in \bbZ} (c_n''(t) + c^2 n^2 c_n(t)) e^{inx} = 0 $$
	da cui si ottiene (visto che $e^{inx}$ è una base di $\cC^0$) il seguente problema:
	$$ \left\{ \begin{array}{c} c_n''(t) + c^2 n^2 c_n(t) = 0 \\ c_n(0) = c_n \\ c_n'(0) = d_n \\ \end{array} \right. $$
	dove $c_n$ e $d_n$ sono i coefficienti della serie di fourier di $u(0, x)$ e di $u_t(0, x)$. \\
	La soluzione del sistema è $c_n(t)  = \frac{1}{2} (c_n + \frac{d_n}{icn}) e^{icnt} + \frac{1}{2} (c_n - \frac{d_n}{icn}) e^{-icnt}$ per $n \neq 0$, mentre per $n = 0$ sappiamo che la soluzione è banalmente $c_0(t) = c_0 + d_0 t$
	
	\subsection*{Equazione del Calore}
	\subsection*{Equazione di Poisson / Laplace}
	
	\section*{Proiezione su un convesso}
	Sia $H$ uno spazio di Hilbert e $K \subset H$ un convesso chiuso. Allora si ha che:
	\begin{itemize}
		\item $\exists ! P_K: H \rar K$, chiamata mappa di proiezione, tale che $\forall x \in H$ si ha $\norm{x - P_K(x)} = \min_{y \in K} \norm{x - y}$.
		\item Il proiettato è "sul bordo" del convesso, ovvero $\forall w \in K$ si ha $\scal{x - P_K x}{w - P_K x} \le 0$
		\item La mappa di proiezione è lipschitziana, ovvero $\forall f, g \in X$ si ha $\norm{P_K f - P_K g} \le \norm{f - g}$
	\end{itemize}
	Inoltre, supponendo che $K$ sia un sottospazio vettoriale chiuso si ha che:
	\begin{itemize}
		\item "La congiungente $x$ e $P_K(x)$ è ortogonale a $K$", ovvero $\forall w \in K \quad \scal{x - P_K(x)}{w} = 0$
		\item $H = K \oplus K^\bot$
		\item La proiezione $P_K$ è lineare ed inoltre vale $\norm{P} = 1$ (dove la norma è quella operatoriale)
		\item Definendo $Q = I - P$ si ha, $\forall x \in H$ la decomposizione seguente:
			\begin{itemize}
				\item $x = P(x) + Q(x)$
				\item $\scal{P(x), Q(x)} = 0$
				\item $\norm{x}^2 = \norm{P(x)}^2 + \norm{Q(x)}^2$
			\end{itemize}
	\end{itemize}
	
	\subsection*{Esistenza}
	Ad $x$ fissato si prenda una successione di $y_n \in K$ che tendono all'$\inf_{y \in K} \norm{y - x}$. Vogliamo mostrare che è una successione di Cauchy: in questo modo, per completezza dell'Hilbert, avremmo che $y_n \rar y_\infty \in H$ e per chiusura di $K$ si ha $y_\infty \in K$, da cui potremmo definire $P(x) = y_\infty$. \\
    Chiamiamo ora $d_n = \norm{x - y_n}$ ed abbiamo che $d_n \rar d = \inf_n \norm{x - y_n}$. Utilizzando l'identità del parallelogramma si ha, se $n, m > N$ che vale:
    $$ \norm{\frac{(x - y_n) + (x - y_m)}{2}}^2 + \norm{\frac{(x - y_n) - (x - y_m)}{2}}^2 = \frac{1}{2} ( \norm{x - y_n}^2 + \norm{x - y_m}^2) $$
    ovvero, riscrivendo che:
    $$ \norm{x - \frac{y_n + y_m}{2}}^2 + \norm{\frac{y_n - y_m}{2}}^2 = \frac{1}{2}(d_n^2 + d_m^2) $$
    Ma sappiamo che per convessità si ha $\frac{y_n + y_m}{2} \in K$ e quindi, per definizione di estremo inferiore si ha $\norm{x - \frac{y_n + y_m}{2}}^2 \ge d^2$ e quindi $\norm{\frac{y_n - y_m}{2}} \le \frac{1}{2}(d_n^2 + d_m^2) - d^2 = \frac{1}{2}(d_n^2 - d^2) + \frac{1}{2}(d_m^2 - d^2) \le \varepsilon$ \\
    Ciò significa che la successione $y_n$ è di cauchy in $H$ da cui segue la tesi.
    
    \subsection*{Unicità}
    Supponiamo per assurdo che esistano due punti che realizzano il minimo, e li denotiamo con $p$ e $q$. (ovviamente dipendono da $x$, ma qui li stiamo pensando ad $x$ fissato). Allora dall'identità del parallelogramma si ha
    $$ \norm{x - \frac{p + q}{2}}^2 + \norm{\frac{p - q}{2}}^2 = \frac{1}{2} (\norm{x - p}^2 + \norm{x - q}^2) = d^2 $$
    Allora siccome, come prima, $\frac{p + q}{2} \in K$ per convessità, si ha che $\norm{\frac{p - q}{2}}^2 \le d^2 - d^2 = 0$, da cui segue $p = q$.
    
    \subsection*{Proiettato sul Bordo}
    Diciamo che il proiettato sta "sul bordo" (non in maniera propria) del convesso (come è abbastanza intuitivo che sia facendo un disegno in $\bbR^2$) e lo esprimiamo dicendo che il segmento che congiunge $x$ a $P_K x$ è "dalla parte opposta" (ovvero ha prodotto scalare negativo) rispetto ad ogni segmento che congiunge un qualunque punto $w$ del compatto a $P_K x$. \\
    Lemma preliminare: Sia $f: [a, b] \rar \bbR$ derivabile e supponiamo che in $a$ vi sia un minimo. Allora $f'(a) \ge 0$ (Dove il limite è inteso sulla parte che sta dentro al dominio di definizione). Dunque, se $f: K \subseteq \bbR^d \rar \bbR$ è $\cC^1$ e definiamo $\phi(t) = f(x_0 + t(x - x_0))$ per $t \in [0, 1]$, allora si ha che $\phi'(0) = \scal{\nabla f(x_0)}{x - x_0} \ge 0$. \\
    Definiamo ora $\Psi(t) = \norm{x - ((1 - t) P_K(x) + t w)}^2$. Per il lemma precedente si ha $\Psi'(0) \ge 0 \quad \forall w \in K$. Ma sappiamo che $\Psi(t) = \norm{x - P_K(x) + t(P_K(x) - w)}^2 = \norm{x - P_K(x)}^2 + 2t \scal{x - P_K(x)}{P_K(x) - w} + t^2 \norm{P_K(x) - w}^2$ e quindi $\Psi'(0) = 2 \scal{x - P_K(x)}{P_K(x) - w} \le 0 \quad \forall w \in K$ \\
    (In realtà, ma non lo dimostriamo, vale anche il viceversa: se il punto $P_K(x)$ gode della proprietà precedente, allora è il punto di proiezione)
    
    \subsection*{Lipschitzianità}
    Sappiamo che $\scal{x - P_K(x)}{w - P_K(x)} \le 0$ e ci giochiamo la disuguaglianza con $(x, w) = (f, P_K(g)) = (g, P_K(f))$, ovvero si ottiene:
    $$ 0 \ge \scal{f - P_K(f)}{P_K(g) - P_K(f)} + \scal{g - P_K(g)}{P_K(f) - P_K(g)} = \scal{f - P_K(f)}{P_K(g) - P_K(f)} - \scal{g - P_K(g)}{P_K(g) - P_K(f)} = \newline
    \scal{f - P_K(f) - g + P_K(g)}{P_K(g) - P_K(f)} = \scal{f - g}{P_K(g) - P_K(f)} + \scal{P_K(g) - P_K(f)}{P_K(g) - P_K(f)} $$
    Allora si ha
    $$ \norm{P_K(g) - P_K(f)}^2 = \scal{P_K(g) - P_K(f)}{P_K(g) - P_K(f)} \le \scal{g - f}{P_K(g) - P_K(f)} \le \norm{g - f} \norm{P_K(g) - P_K(f)} $$
    E si ottiene la disuguaglianza cercata dividendo per $\norm{P_K(g) - P_K(f)}$
	
	\subsection*{Ortogonalità della congiungente}
	Supponendo ora che $K$ sia un sottospazio vettoriale chiuso possiamo sostituire nella disuguaglianza precedente $w = 0$ e $w = 2 P_K(x)$ ottenendo che $\scal{x - P_K(x)}{P_K(x)} \ge 0$ e $\scal{x - P_K(x)}{P_K(x)} \le 0$, ovvero $\scal{x - P_K(x)}{P_K(x)} = 0$, ma allora otteniamo $\scal{x - P_K(x)}{w} = \scal{x - P_K(x)}{w - P_K(x)} \le 0$. \\
	Inoltre, valendo la disuguaglianza sia per $w$ che per $-w$, si ottiene facilmente che $\scal{x - P_K(x)}{w} = 0$, che è la tesi.
	
	\subsection*{Decomposizione in somma diretta}
	Dato $x \in H$, si ha $x = x - P_K(x) + P_K(x)$. Notiamo ora che $P_K(x) \in K$ e che, per quanto detto prima, $x - P_K(x) \in K^\bot$
	
	\subsection*{La proiezione è lineare e di norma unitaria}
	Per vedere che è lineare, basta osservare che:
	$$ \left\{ \begin{array}{cc} \scal{\alpha x + \beta y - P_K(\alpha x + \beta y), w} = 0 & \forall w \in K \\
	\scal{\alpha x + \beta y - \alpha P_K(x) - \beta P_K(y)}{w} = 0 & \forall w \in K \\ \end{array} \right. $$
	Allora $\scal{P_K(\alpha x + \beta y) - \alpha P_K(x) - \beta P_K(y)}{w} = 0 \quad \forall w \in K$ ma poiché $P_K(\alpha x + \beta y) - \alpha P_K(x) - \beta P_K(y) \in K$ si ha $\norm{P_K(\alpha x + \beta y) - \alpha P_K(x) - \beta P_K(y)} = 0$ e quindi $P_K(\alpha x + \beta y) = \alpha P_K(x) + \beta P_K(y)$. \\
	Si ha inoltre che $\norm{x} \norm{P_K(x)} \ge \scal{x}{P_K(x)} = \scal{P_K(x)}{P_K(x)} = \norm{P_K(x)}^2$ e quindi $\norm{P} \le 1$, ma preso $k \in K$ si ha che $P_K(k) = k$ e quindi $\norm{P} \ge 1$, ovvero $\norm{P} = 1$.
	
	\section*{Riesz-Fisher}
	Sia $f \in \Lincont(H, \bbR)$ continuo e limitato e lineare, con $H$ spazio di Hilbert. Allora $\exists ! y \in H$ tale che $f(x) = \scal{x, y} \quad \forall x \in H$ \\
	
	\subsection*{Lemma della codimensione}
	Dato $H$ spazio di Hilbert e $f \in \Lincont(H, \bbR)$ continuo e limitato e lineare non nullo si ha che $\codim \Ker f = 1$ \\
	
	Sia $y \in H$ tale che $f(y) \neq 0$. Allora definiamo $\lambda = \frac{1}{f(y)}$ in modo che $f(\lambda y) = 1$. Sia ora $y_0 = \lambda y$. Dato un qualunque $x \in H$ si ha $x = x - f(x)y_0 + f(x)y_0$, con $x - f(x)y_0 \in \Ker f$. Inoltre tale decomposizione è unica, in quanto se $x = x' + \alpha y_0 = x'' + \beta y_0$ con $x', x'' \in \Ker f$ allora si ha $f(x) = \alpha = \beta$ e dunque $x' = x''$. Concludiamo quindi che $H = \Ker f \oplus \Span(y_0)$, che è la tesi.
	
	\subsection*{Esistenza}
	Supponiamo $f \neq 0$ e chiamiamo $K = \Ker f$. Allora $K$ è un sottospazio lineare chiuso di codimensione $1$. Chiamiamo quindi $P$ la proiezione su $K$. Visto che $H = K \oplus K^\bot$ e $K^\bot = Span(y_0)$ con $f(y_0) = 1$, allora dato $h \in H$ si può scomporre come $x = \lambda y_0 + z$ con $z \in \Ker f = K$. \\
	Allora $f(x) = \lambda f(y_0) = \lambda$ e si ha $\scal{x}{y_0} = \lambda \scal{y_0}{y_0} = \lambda \norm{y_0}^2$ dunque ponendo $y = \frac{y_0}{\norm{y_0}^2}$ si ha l'esistenza. \\
	
	\subsection*{Unicità}
	Supponiamo ora che esistano due elementi $y, w$ che rappresentano $f$. Allora $\scal{x, y - w} = 0 \quad \forall x \in H$ e quindi in particolare $\norm{y - w}^2 = 0 \implies y = w$
	
	\section*{Funzioni Armoniche}
	
	\section*{Serie e Trasformata di Fourier}
	\subsection*{Definizioni e Proprietà}
	\subsection*{Approssimanti}
	
	\section*{Riemann-Lebesgue}
\end{document}
